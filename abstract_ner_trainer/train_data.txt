Age-associated B cells (ABCs) accumulate with age, as well as in individuals with a range of immunological dyscrasias. These include patients with cancer treated with immune checkpoint blockade and patients with inborn errors of immunity. In this study, we sought to determine whether ABCs found in all these conditions are similar, and whether they enhance or detract from the response to COVID-19 vaccination. We use single cell RNA sequencing to show that ABCs arising from distinct aetiologies have common transcriptional profiles and may be subdivided according to the expression of genes associated with different immune functions, such as the autoimmune regulator (AIRE). Next, we perform detailed longitudinal profiling of the COVID-19 vaccination response in patients and controls. We show that high pre-vaccination ABC frequency correlates with decreased levels of antigen-specific memory B cells, and reduced magnitude and longevity of neutralising capacity against SARS-CoV-2 virus. Potentially contributing to this, ABCs express high levels of the inhibitory FcγRIIB receptor and are distinctive in their ability to bind immune complexes. This could contribute to diminished vaccine responses either directly as result of inhibitory signalling or indirectly via enhanced clearance of immune complexed-antigen. Expansion of ABCs may therefore serve as a biomarker identifying individuals at risk of a suboptimal response to COVID-19 vaccination.

We aimed to assess the prevalence of asymptomatic cases of monkeypox virus (MPXV) infection among gay, bisexual, and other men who have sex with men and trans women (TW), using a self-sampling strategy. Anal and pharyngeal swabs were tested by MPXV real-time PCR and positive samples inoculated into Vero E6 cells, which were subsequently checked for cytopathic effect (CPE).  Seven out 113 participants were MPXV positive (6.19% (95% CI: 1.75%-10.64%)). Five tested positive in pharyngeal swabs, one in anal swab and one in both. Six did not present symptoms recognized as MPXV infection. Three samples were positive for CPE, and showed anti-vaccinia pAb staining by FACS and confocal microscopy.  We describe Mpox cases that remain undiagnosed and show reproductive virus despite low viral loads and who might be able to infect others. Restricting testing to individuals reporting Mpox symptoms may not be enough to contain outbreaks.

Background: Clinicopathological features are used for detection of diseases. Early detection of cancer can be significance for understanding the behavior of disease.  Results: We developed a tool to observe stomach adenocarcinoma in reference of blood-lipid profile. Background of the tool is based on the study made on RNAseq expression analysis of stomach adenocarcinoma. Raw data for study was collected as gene-expression profile from population of cancer-vs-normal. A series of studies performed including: differential gene expression analysis, plasma proteome mapping, extraction of gene-signature enriched with LSTM system model, AI-guided simulation of systems model of gene network, and AI-guided mapping with blood lipid profile to develop R-Shiny web-application.  Conclusion: EarlyDetect, is freely available at https://csir-icmr.shinyapps.io/EarlyDetect/. The tool can be utilized for (i) virtual observation of impact of different combinations of lipid profile in cancer progression; (ii) early detection of cancer state for new comer patients.

Aims: Type 1 diabetes (T1D) results from an autoimmune attack of the pancreatic beta cells that progresses to dysglycemia and symptomatic hyperglycemia. Current biomarkers to track this evolution are limited, with development of islet autoantibodies marking the onset of autoimmunity and metabolic tests used to detect dysglycemia. Therefore, additional biomarkers are needed to better track disease initiation and progression. Multiple clinical studies have used proteomics to identify biomarker candidates. However, most of the studies were limited to the initial candidate identification, which needs to be further validated and have assays developed for clinical use. Here we curate these studies to help prioritize biomarker candidates for validation studies and to obtain a broader view of processes regulated during disease development.  Methods: This systematic review was registered with Open Science Framework (DOI 10.17605/OSF.IO/N8TSA). Using PRISMA guidelines, we conducted a systematic search of proteomics studies of T1D in the PubMed to identify putative protein biomarkers of the disease. Studies that performed mass spectrometry-based untargeted/targeted proteomic analysis of human serum/plasma of control, pre-seroconversion, post-seroconversion, and/or T1D-diagnosed subjects were included. For unbiased screening, 3 reviewers screened all the articles independently using the pre-determined criteria. Results: A total of 13 studies met our inclusion criteria, resulting in the identification of 251 unique proteins, with 27 (11%) being identified across 3 or more studies. The circulating protein biomarkers were found to be enriched in complement, lipid metabolism, and immune response pathways, all of which are found to be dysregulated in different phases of T1D development. We found a subset of 3 proteins (C3, KNG1 & CFAH), 6 proteins (C3, C4A, APOA4, C4B, A2AP & BTD) and 7 proteins (C3, CLUS, APOA4, C6, A2AP, C1R & CFAI) have consistent regulation between multiple studies in samples from individuals at pre-seroconversion, post-seroconversion and post-diagnosis compared to controls, respectively, making them strong candidates for clinical assay development. Conclusions: Biomarkers analyzed in this systematic review highlight alterations in specific biological processes in T1D, including complement, lipid metabolism, and immune response pathways, and may have potential for further use in the clinic as prognostic or diagnostic assays.

Background: Per- and polyfluoroalkyl substances (PFAS) are a growing class of manufactured chemical compounds found in a variety of consumer products. PFAS have become ubiquitous in the environment and were found in many humans sampled in the United States (U.S.). Yet, significant gaps in understanding statewide level exposures to PFAS remain.  Objective: The goals of this study are to establish a baseline of exposure at the state level by measuring PFAS serum levels among a representative sample of Wisconsin residents and compare to United States National Health and Nutrition Examination Survey (NHANES). Methods: The study sample included 605 adults (18+ years of age) selected from the 2014-2016 sample of the Survey of the Health of Wisconsin (SHOW). Thirty-eight PFAS serum concentrations were measured using high-pressure liquid chromatography coupled with tandem mass spectrometric detection (HPLC-MS/MS) and geometric means presented. Weighted geometric mean serum values of eight PFAS analytes from SHOW were compared to U.S. national levels from the NHANES 2015-2016 sample (PFOS, PFOA, PFNA, PFHxS, PFHpS, PFDA, PFUnDA), and the 2017-2018 sample for Me-PFOSA, PFHPS using the Wilcoxon rank-sum test.  Results: Over 96% of SHOW participants had positive results for PFOS, PFHxS, PFHpS, PFDA, PFNA, and PFOA. In general, SHOW participants had lower serum levels across all PFAS when compared to NHANES. Serum levels increased with age and were higher among males and whites. These trends were seen in NHANES, except non-whites had higher PFAS levels at higher percentiles.  Significance: Wisconsin residents may have a lower overall body burden of some PFAS compounds compared to those seen by a nationally representative sample. Additional testing and characterization may be needed in Wisconsin, particularly among non-whites and low socioeconomic status, for which the SHOW sample had less representation compared to NHANES.

Background: Patients with Parkinson's disease undergo a loss of melanized neurons in substantia nigra pars compacta (SNc) and locus coeruleus (LC). There are very few in vivo studies of LC pathology in Parkinson's disease with magnetic resonance imaging (MRI). Existing studies have used varying methodologies, and reproducibility has not been established for any approach.  Methods: Two cohorts, discovery and validation, were recruited from the Emory Movement Disorders Clinic and scanned on two different MRI scanners. In cohort 1, imaging data from 19 controls and 22 Parkinson's disease patients were acquired with a Siemens Trio 3 Tesla scanner using a 2D gradient echo sequence with magnetization transfer preparation pulse. Cohort 2 consisted of 33 controls and 39 Parkinson's disease patients who were scanned on a Siemens Prisma 3 Tesla scanner with a similar imaging protocol. LC and SNc volumes were segmented in both cohorts.  Results:  SNc volume (Cohort 1: p=0.0148; Cohort 2: p=0.0011) and LC volume (Cohort 1: p=0.0412; Cohort 2: p=0.0056) were significantly reduced in the Parkinson's disease group as compared to controls in both cohorts.  Conclusion: SNc volume and LC volume were significantly reduced in Parkinson's disease compared to controls in both cohorts. This imaging approach robustly detects Parkinson's disease effects on these structures, indicating that it is a promising marker for neurodegenerative neuromelanin loss.

ABSTRACT  Introduction The nirmatrelvir/ritonavir (PAXLOVIDTM) is an antiviral blocking the replication of SARS-CoV-2. Early treatment with this antiviral has showed to reduce COVID-19 hospitalization and death in unvaccinated outpatients with mild-to-moderate COVID-19 and high risk of progression to severe disease with variants before Omicron. However, the current epidemiological context and the level of immunity in the population (vaccination and/or natural infection) have evolved considerably since the disclosure of these results. Thus, real-world evidence studies in vaccinated outpatients with lineage and sublineage of the variant are needed.  Objective To assess whether nirmatrelvir/ritonavir treatment reduces the risk of COVID-19-associated hospitalization among Québec outpatients with mild-to-moderate COVID-19 at high risk of progression to severe disease in a real-world context, regardless of vaccination status and circulating variants, in the province of Québec.  Methods This was a retrospective cohort study of SARS-CoV-2-infected outpatients who received nirmatrelvir/ritonavir between March 15 and August 15, 2022, using data from the Québec provincial clinico-administrative databases. Outpatients treated with nirmatrelvir/ritonavir were compared to unexposed ones. The treatment group was matched with controls using propensity-score matching in a ratio of 1:1. The outcome was COVID-19-associated hospitalization occurring within 30 days following the index date. Poisson regression with robust error variance was used to estimate the relative risk of hospitalization among the treatment group compared to the control group.   Results A total of 16,601 and 242,341 outpatients were eligible to be included in the treatment (nirmatrelvir/ritonavir) and control groups respectively. Among treated outpatients, 8,402 were matched to controls. Regardless of vaccination status, nirmatrelvir/ritonavir-treated outpatient status was associated with a 69% reduced relative risk of COVID-19-associated hospitalization (RR: 0.31 [95% CI: 0.28; 0.36]). The effect was more pronounced in outpatients without a complete primary vaccination course (RR: 0.04 [95% CI: 0.03; 0.06]), while treatment with nirmatrelvir/ritonavir was not associated with benefit when outpatients with a complete primary vaccination course were considered (RR: 0.93 [95% CI: 0.78; 1.08]) Subgroups analysis among outpatients with a primary vaccination course showed that nirmatrelvir/ritonavir treatment was associated with a significant decrease in relative risk of hospitalization in severely immunocompromised outpatients (RR: 0.66 [95% CI: 0.50; 0.89]) and in outpatients aged 70 years and older (RR: 0.50 [95% CI: 0.34; 0.74]) when the last dose of the vaccine was received more than six months before.  Conclusions Among SARS-CoV-2 infected outpatients at high risk for severe COVID-19 during Omicron BA.2 and BA.4/5 surges, treatment with nirmatrelvir/ritonavir was associated with a significant reduced relative risk of COVID-19-associated hospitalization. This effect was observed in outpatients with incomplete primary vaccination course and in outpatients who were severely immunocompromised. Except for severely immunocompromised outpatients, no evidence of benefit was found in any category of outpatient with a complete primary vaccination course whose last dose of COVID-19 vaccine was received within six months.

Objective: To investigate the diagnostic and prognostic role of gastric fluid DNA (gfDNA) in gasric cancer (GC) patients and controls submitted to upper digestive endoscopy. Design: The concentration of gfDNA was evaluated in 941 samples, including subjects with normal gastric mucosa (n = 10), peptic diseases (n = 596), pre-neoplastic conditions (n = 99), and cancer (n = 236). gfDNA levels were evaluated according to age, gender, BMI, gastric fluids pH, use of proton-pump inhibitors, GC tumor subtypes, histological grades, clinical stages, and disease progression/outcome. Results: In the non-cancer group, we observed that gfDNA levels are increased in women as compared to men (p=7.44e-4). Remarkably, gfDNA levels are increased in GC patients as compared to non-GC (normal + peptic diseases, p=5.67e-13) and in GC versus pre-neoplastic disease (p=1.53e-6). Similar differences were also seen when more advanced tumors (T3) were compared to early stages (T2 and below) (p=5.97-4). Moreover, our results suggest the prognostic value of gfDNA as GC-patients with higher gfDNA concentrations (<1.28ng/microliter) had increased infiltration of immune cells in the tumor (p=1.06e-3), which parallels with better disease-free survival (p= 0.014). Conclusion: These findings highlight the significance of collecting and studying stomach fluids from gastric cancer patients and reveals the potential impact of this approach as well as its diagnostic and prognostic value for disease management.

Because of the large number of infected individuals, an estimate of the future burdens of the long-term consequences of SARS-CoV-2 infection is needed. This systematic review examined associations between SARS-CoV-2 infection and incidence of categories of and selected chronic conditions, by age and severity of infection (inpatient vs. outpatient/mixed care). MEDLINE and EMBASE were searched (Jan 1, 2020 to Oct 4, 2022) and reference lists scanned. We included observational studies from high-income OECD countries with a control group adjusting for sex and comorbidities. Identified records underwent a two-stage screening process. Two reviewers screened 50% of titles/abstracts, after which DistillerAI acted as second reviewer. Two reviewers then screened the full texts of stage one selections. One reviewer extracted data and assessed risk of bias; results were verified by another. Random-effects meta-analysis estimated pooled hazard ratios (HR). GRADE assessed certainty of the evidence. Twenty-five studies were included. Among the outpatient/mixed SARS-CoV-2 care group, there is high certainty of a small-to-moderate increase (i.e., HR 1.26 to 1.99) among adults ≥65 years of any cardiovascular condition, and of little-to-no difference (i.e., HR 0.75 to 1.25) in anxiety disorders for individuals <18, 18-64, and ≥65 years old. Among 18-64 and ≥65 year-olds receiving outpatient/mixed care there are probably (moderate certainty) large increases (i.e., HR ≥2.0) in encephalopathy, interstitial lung disease, and respiratory failure. After SARS-CoV-2 infection, there is probably an increased risk of diagnoses for some chronic conditions; whether the magnitude of risk will remain stable into the future is uncertain.

Generative artificial intelligence, popularized by services like ChatGPT, has been the source of much recent popular attention for publishing health research. Another valuable application is in translating published research studies to readers in non-academic settings. These might include environmental justice communities, mainstream media outlets, and community science groups. Five recently published (2021-2022) open-access, peer-reviewed papers, authored by University of Louisville environmental health investigators and collaborators, were submitted to ChatGPT. The average rating of all summaries of all types across the five different studies ranged between 3 and 5, indicating good overall content quality. ChatGPT's general summary request was consistently rated lower than all other summary types. Whereas higher ratings of 4 and 5 were assigned to the more synthetic, insight-oriented activities, such as the production of a plain language summaries suitable for an 8th grade reading level and identifying the most important finding and real-world research applications. This is a case where artificial intelligence might help level the playing field, for example by creating accessible insights and enabling the large-scale production of high-quality plain language summaries which would truly bring open access to this scientific information. This possibility, combined with the increasing public policy trends encouraging and demanding free access for research supported with public funds, may alter the role journal publications play in communicating science in society. For the field of environmental health science, no-cost AI technology such as ChatGPT holds the promise to improve research translation, but it must continue to be improved (or improve itself) from its current capability.

Background and Objectives: Valproate is a candidate for ischemic stroke prevention due to its anti-atherosclerotic effects in vivo. Although valproate use is associated with decreased ischemic stroke risk in observational studies, confounding by indication precludes causal conclusions. To overcome this limitation, we applied Mendelian randomization to determine whether genetic variants that influence clinical response among valproate users associate with ischemic stroke risk in the UK Biobank (UKB). Methods: Using independent genome-wide association data of seizure response after valproate intake from the EpiPGX consortium, a genetic score for valproate response was derived. Valproate users were identified from UKB baseline and primary care data, and the association of the genetic score with incident and recurrent ischemic stroke was tested in Cox proportional hazard models. Results: Among 2,150 valproate users (mean 56 years, 54% females), 82 ischemic strokes occurred over a mean 12-year follow-up. A higher genetic score was associated with an increased effect of valproate dose on serum valproate levels (+0.48 mcg/ml per 100mg/day per one SD, 95%CI[0.28, 0.68]). After adjusting for age and sex, a higher genetic score was associated with lower ischemic stroke risk (HR per one SD 0.73, [0.58, 0.91]) with a halving of absolute risk in the highest compared to the lowest score tertile (4.8% vs 2.5%, p-trend=0.027). In the 194 valproate users with prevalent stroke at baseline, a higher genetic score was associated with lower recurrent ischemic stroke risk (HR per one SD 0.53, [0.32, 0.86]) with reduced absolute risk in the highest compared to the lowest score tertile (3/51, 5.9% vs. 13/71, 18.3%, p-trend=0.026). The genetic score was not associated with ischemic stroke among the 427,997 valproate non-users (p=0.61), suggesting minimal contribution of pleiotropic effects from included genetic variants.  Discussion: Among valproate users, genetically predicted favorable seizure response to valproate was associated with higher valproate levels and reduced ischemic stroke risk, providing causal support for valproate utility in ischemic stroke prevention. The strongest effect was found for recurrent ischemic stroke, suggesting potential dual-use benefits of valproate for post-stroke epilepsy. Clinical trials are warranted to identify populations that may benefit most from valproate for stroke prevention.

Background: Population genetics is crucial for understanding the transmission dynamics of diseases like onchocerciasis. Landscape genetics identifies the ecological features that impact genetic variation between sampling sites. Here, we have used a landscape genetics framework to understand the relationship between environmental features and gene flow of the filarial parasite Onchocerca volvulus and of its intermediate host and vector, blackflies in the genus Simulium. We analysed samples from the ecological transition region separating the savannah and forest ecological regions of Ghana, where the transmission of O. volvulus has persisted despite almost half a century of onchocerciasis control efforts.   Methods: We generated a baseline microfilarial prevalence map from the point estimates of pre-ivermectin microfilarial prevalence from 47 locations in the study area. We analysed mitochondrial data from 164 parasites and 93 blackflies collected from 15 communities and four breeding sites, respectively. We estimated population genetic diversity and identified correlations with environmental variables. Finally, we compared baseline prevalence maps to movement suitability maps that were based on significant environmental variables.   Results: We found that the resistance surfaces derived from elevation (r = 0.793, p = 0.005) and soil moisture (r = 0.507, p = 0.002) were significantly associated with genetic distance between parasite sampling locations. Similarly, for the vector populations, the resistance surfaces derived from soil moisture (r = 0.788, p = 0.0417) and precipitation (r = 0.835, p = 0.0417) were significant. The correlation between the baseline parasite prevalence map and the parasite resistance surface map was stronger than the correlation between baseline prevalence and the vector resistance surface map. The central parts of the transition region which were conducive for both the parasite and the vector gene flow were most strongly associated with high baseline onchocerciasis prevalence.   Conclusions: We present a framework for incorporating environmental, genetic, and prevalence data for identifying when ecological conditions are favourable for onchocerciasis transmission between communities. We identified areas with higher suitability for parasite and vector gene flow, which ultimately might help us gain deeper insights into defining transmission zones for onchocerciasis. Furthermore, this framework is translatable to other onchocerciasis endemic areas and to other vector-borne diseases.

Objectives: Copy number variants (CNVs) are well-known genetic pleiotropic risk factors for multiple neurodevelopmental and psychiatric disorders (NPDs) including autism (ASD) and schizophrenia (SZ). Overall, little is known about how different CNVs conferring risk for the same condition may affect subcortical brain structures and how these alterations relate to the level of disease risk conferred by CNVs. To fill this gap, we investigated gross volume, and vertex level thickness and surface maps of subcortical structures in 11 different CNVs and 6 different NPDs. Methods: Subcortical structures were characterized using harmonized ENIGMA protocols in 675 CNV carriers (at the following loci: 1q21.1, TAR, 13q12.12, 15q11.2, 16p11.2, 16p13.11, and 22q11.2) and 782 controls (Male/Female: 727/730; age-range: 6-80 years) as well as ENIGMA summary-statistics for ASD, SZ, ADHD, Obsessive-Compulsive-Disorder, Bipolar-Disorder, and Major-Depression. Results: Nine of the 11 CNVs affected volume of at least one subcortical structure. The hippocampus and amygdala were affected by five CNVs. Effect sizes of CNVs on subcortical volume, thickness and local surface area were correlated with their previously reported effect sizes on cognition and risk for ASD and SZ. Shape analyses were able to identify subregional alterations that were averaged out in volume analyses. We identified a common latent dimension - characterized by opposing effects on basal ganglia and limbic structures - across CNVs and across NPDs. Conclusion: Our findings demonstrate that subcortical alterations associated with CNVs show varying levels of similarities with those associated with neuropsychiatric conditions. We also observed distinct effects with some CNVs clustering with adult conditions while others clustered with ASD. This large cross-CNV and NPDs analysis provide insight into the long-standing questions of why CNVs at different genomic loci increase the risk for the same NPD, as well as why a single CNV increases the risk for a diverse set of NPDs.

Acoustic signal analysis has been employed in various medical devices. However, studies involving cough sound analysis to screen the potential Pulmonary Tuberculosis (PTB) suspects are very few. The main objective of this cross-sectional validation study was to develop and validate the Swaasa AI platform to screen and prioritize at risk patients for PTB based on the signature cough sound as well as symptomatic information provided by the subjects. The voluntary cough sound data was collected at Andhra Medical College-India. An Algorithm based on multimodal Convolutional Neural Network (CNN) architecture and Feedforward Artificial Neural Network (FFANN) (tabular features) was built and validated on a total of 567 subjects, comprising 278 positive and 289 negative PTB cases. The output from these two models was combined to detect the likely presence (positive cases) of PTB. In the clinical validation phase, the AI-model was found to be 86.82% accurate in detecting the likely presence of PTB with 90.36% sensitivity and 84.67% specificity. The pilot testing of model was conducted at a peripheral health care centre, RHC Simhachalam-India on 65 presumptive PTB cases. Out of which, 15 subjects truly turned out to be PTB positive with a Positive Predictive Value of 75%. The validation results obtained from the model are quite encouraging. This platform has the potential to fulfil the unmet need of a cost-effective PTB screening method. It works remotely, presents instantaneous results, and does not require a highly trained operator. Therefore, it could be implemented in various inaccessible, resource-poor parts of the world.

Introduction Deep brain stimulation (DBS) is an established treatment in patients with pharmaco-resistant neurological disorders of different ages. Surgical targeting and postoperative programming of DBS depend on the spatial location of the stimulating electrodes in relation to the surrounding anatomical structures and on electrode connectivity to a specific distributed pattern of brain networks. Such information is usually collected using group-level analysis which relies on the availability normative imaging-resources (atlases and connectomes). To this end, analyzing DBS data of children with debilitating neurological disorders like dystonia would make benefit from such resources, especially given the developmental differences between adults and children neuroimaging data. We assembled pediatric, normative neuroimaging-resources from open-access neuroimaging datasets and illustrated their utility on a cohort of children with dystonia treated with pallidal DBS. We aimed to derive a local pallidal sweetspot and explore a connectivity fingerprint associated with pallidal stimulation to exemplify the utility of the assembled imaging resources.  Methods A pediatric average brain template was implemented and used to localize DBS electrodes of twenty patients of the GEPESTIM registry cohort.  Next, a pediatric subcortical atlas was also employed to highlight anatomical structures of interest. Local pallidal sweetspot was modeled and its degree of overlap with stimulation volumes was calculated as a correlate of individual clinical outcome. Additionally, a pediatric functional connectome of neurotypical subjects was built to allow network-based analyses and decipher a connectivity fingerprint responsible for clinical improvement in our cohort.  Results We successfully implemented a pediatric neuroimaging dataset that will be made available to public use as a tool for DBS-analyses. Overlap of stimulation volumes with the identified DBS-sweetspot model correlated significantly with improvement on a local spatial level (R = 0.46, permuted p = 0.019). Functional connectivity fingerprint of DBS-outcome was determined as a network correlate of therapeutic pallidal stimulation in children with dystonia (R = 0.30, permuted p = 0.003).   Conclusions Local sweetspot and distributed network models provide neuroanatomical substrates for DBS-associated clinical outcome in dystonia using pediatric neuroimaging surrogate data. The current implementation of pediatric neuroimaging dataset might help improving the practice of DBS-neuroimaging analyses in pediatric patients.

Oral squamous cell carcinoma (OSCC) is amongst the most common cancers worldwide, with more than 377,000 new cases worldwide each year. OSCC prognosis remains poor, related to cancer presentation at a late stage indicating the need for early detection to improve patient prognosis. OSCC is often preceded by a premalignant state known as oral epithelial dysplasia (OED), which is diagnosed and graded using subjective histological criteria leading to variability and prognostic unreliability. In this work, we propose a deep learning approach for the development of prognostic models for malignant transformation and their association with clinical outcomes in histology whole slide images (WSIs) of OED tissue sections. We train a weakly supervised method on OED (n= 137) cases with transformation (n= 50) status and mean malignant transformation time of 6.51 years (±5.35 SD). Performing stratified 5-fold cross-validation achieves an average AUROC of ~0.78 for predicting malignant transformations in OED. Hotspot analysis reveals various features from nuclei in the epithelium and peri-epithelial tissue to be significant prognostic factors for malignant transformation, including the count of peri-epithelial lymphocytes (PELs) (p < 0.05), epithelial layer nuclei count (NC) (p < 0.05) and basal layer NC (p < 0.05). Progression free survival using the Epithelial layer NC (p < 0.05, C-index = 0.73), Basal layer NC (p < 0.05, C-index = 0.70) and PEL count (p < 0.05, C-index = 0.73) shown association of these features with a high risk of malignant transformation. Our work shows the application of deep learning for prognostication and progression free survival (PFS) prediction of OED for the first time and has a significant potential to aid patient management. Further evaluation and testing on multi-centric data is required for validation and translation to clinical practice.

Typhoid-conjugate vaccines (TCVs) provide an opportunity to reduce the burden of typhoid fever, caused by Salmonella Typhi, in endemic areas. As policymakers design vaccination strategies, accurate and high-resolution data on disease burden is crucial. However, traditional blood culture-based surveillance is resource-extensive, prohibiting its large-scale and sustainable implementation. Salmonella Typhi is a water-borne pathogen, and here, we tested the potential of Typhi-specific bacteriophage surveillance in surface water bodies as a low-cost tool to identify where Salmonella Typhi circulates in the environment. In 2021, water samples were collected and tested for the presence of Salmonella Typhi bacteriophages at two sites in Bangladesh: urban capital city, Dhaka, and a rural district, Mirzapur. Salmonella Typhi-specific bacteriophages were detected in 66 of 211 (31%) environmental samples in Dhaka, in comparison to 3 of 92 (3%) environmental samples from Mirzapur. In the same year, 4,620 blood cultures at the two largest pediatric hospitals of Dhaka yielded 215 (5%) culture-confirmed typhoid cases, and 3,788 blood cultures in the largest hospital of Mirzapur yielded 2 (0.05%) cases. 75% (52/69) of positive phage samples were collected from sewage. All isolated phages were tested against a panel of isolates from different Salmonella Typhi genotypes circulating in Bangladesh and were found to exhibit a diverse killing spectrum, indicating diverse bacteriophages were isolated. These results suggest an association between the presence of Typhi-specific phages in the environment and the burden of typhoid fever, and the potential of utilizing environmental phage surveillance as a low-cost tool to assist policy decisions on typhoid control.

Abstract  Importance: Consistent, evidence-based communication is critical to building trust and maintaining credibility of public health agencies. Objective: To identify any significant changes in the mainstream media's presentation of public health advice for flu prevention before and after the COVID-19 pandemic.  Design, Setting, and Participants: A systematic search in Factiva of top ten U.S. newspapers by circulation, using two search periods, 2018-2019 and 2021-2022.  Articles with flu prevention advice were identified, abstracted for media outlet, reporter, date. Articles were coded for the specific advice provided.    Main Measure(s): Number of recommendations for flu prevention, frequency of each recommendation; percent of recommendations aligned with CDC guidelines for each period. Changes in frequency of each recommendation. Differences determined using 2-proportion Z-tests, p-value 0.05 significance.  Results: 128 articles with 244 recommendations for pre-COVID period; 122 articles with 296 recommendations post-COVID. 96.3% of recommendations in alignment with CDC guidelines pre-COVID. 63.9% of recommendations in alignment with CDC during post-COVID timeframe. Percentage of articles with advice to mask for flu increased by 1,494.8% (p=<0.00001). 14.5% decline in percentage of articles advising flu vaccine (p=0.002). 495.5% increase in percentage of articles recommending social distancing (p=0.001).  1,368.9% increase in percentage articles recommending increased ventilation (p=0.0004). Advice to cover cough/sneeze declined by 52.8% (p=0.041); advice to disinfect surfaces declined by 76.7% (p=0.038).  Conclusions and Relevance: Expert advice on flu prevention as presented in top 10 U.S. newspapers changed significantly during the COVID-19 pandemic. The strategies discussed more frequently are not currently recommended by CDC. This is relevant information for public health leaders as they address ongoing issues of trust and credibility.

Background: The prognostic utility of NT-proBNP in the setting of hypertension has not been well-characterized in the general US adult population.  Methods: We measured NT-proBNP among adults aged 20 years who participated in the 1999-2004 National Health and Nutrition Examination Survey. In adults without a history of cardiovascular disease, we assessed the prevalence of elevated NT-pro-BNP by blood pressure (BP) treatment and control categories. We examined the extent to which NT-proBNP identifies participants at higher risk for mortality across BP treatment and control categories.  Results: The number of US adults without CVD with elevated NT-proBNP (125 pg/ml) was 6.2 million among those with untreated hypertension, 4.6 million among those with treated controlled hypertension, and 5.4 million among those with treated uncontrolled hypertension. After adjusting for age, sex, body mass index, and race/ethnicity, participants with treated controlled hypertension and elevated NT-proBNP had increased risk of all-cause mortality (HR 2.29, 95% CI 1.79, 2.95) and increased risk of cardiovascular mortality (HR 3.83, 95% CI: 2.34, 6.29), compared to those without hypertension and with low levels of NT-proBNP (<125 pg/ml). Among those on antihypertensive medication, those with SBP 130-139 mm Hg and elevated NT-proBNP had increased risk of all-cause mortality, compared to those with SBP<120 mm Hg and low levels of NT-proBNP.  Conclusions:  Among a general population of adults free of cardiovascular disease, NT-proBNP can provide additional prognostic information within and across categories of BP. Measurement of NT-proBNP may have potential for clinical use to optimize hypertension treatment. 

Background: The routine administration of supplemental oxygen to non-hypoxic patients with acute myocardial infarction has been abandoned for lack of mortality benefit. However, the benefits of continuous positive airway pressure (CPAP) use in patients hospitalized with acute cardiovascular disease and concomitant obstructive sleep apnea (OSA) remain to be elucidated. Methods: Using ICD-10-CM codes, we searched the 2016-2019 Nationwide Inpatient Sample for patients diagnosed with unstable angina, acute myocardial infarction (AMI), acute decompensated heart failure (ADHF), and atrial fibrillation with rapid ventricular response (AFRVR), who also carried a diagnosis of OSA. We identified in-hospital CPAP use with ICD-10-PCS codes. In-hospital death, length of stay (LOS) and hospital charges were compared between patients with and without OSA, and between OSA patients with and without CPAP use. Results: Our sample included 2,959,991 patients, of which 1.5% were diagnosed with UA, 30.3% with AMI, 37.5% with ADHF, and 45.8% with AF. OSA was present in 12.3%. Patients with OSA were more likely to be younger, male, smokers, obese, have chronic obstructive pulmonary disease, renal failure, and heart failure (p < 0.001 for all). Patients with OSA had significantly lower in-hospital mortality (aOR: 0.71, 95% CI [0.7-0.73]). Among patients with OSA, CPAP use significantly increased the odds of in-hospital death (aOR: 1.51, 95% CI [1.44-1.60]), LOS (adjusted mean difference of 1.49 days, 95% CI [1.43, 1.55]), and hospital charges (adjusted mean difference of $1168, 95% CI [273, 2062]). Conclusion: Our study showed that patients with recognized OSA and hospitalized for AMI, ADHF or AFRVR, who were not treated with CPAP, had significantly lower in-hospital mortality and resource utilization. Keywords: Myocardial infarction, Obstructive sleep apnea, Heart failure, Atrial fibrillation, Ischemic preconditioning

Background: The most effective dosage of aspirin to prevent coronary artery abnormalities in patients with acute Kawasaki disease remains unknown. Using a Japanese national inpatient database, this study aimed to identify the appropriate dose of aspirin to be prescribed to patients with acute Kawasaki disease. Method: We used the Diagnostic Procedure Combination database to identify patients with Kawasaki disease treated with intravenous immunoglobulin between 2010 and 2021.The outcomes included the occurrence of coronary artery abnormalities and intravenous immunoglobulin resistance, length of stay, and medical costs. Restricted cubic spline functions were performed to examine the association between aspirin dose and the outcomes. Results: Data of 82109 patients were extracted from the database. Non-linear associations were observed between aspirin dose and the outcomes. In comparison with an aspirin dose of 30 mg/kg/day, the odds ratio (95% confidence interval) for coronary artery abnormalities was 1.40 (1.13-1.75) at 5 mg/kg/day. An aspirin dose of {greater than or equal to}30 mg/kg/day did not significantly change the odds ratio for coronary artery abnormalities. Compared with a dose of 30 mg/kg/day, the odds ratio (95% confidence interval) for intravenous immunoglobulin resistance was 0.87 (0.76-1.00) at 5 mg/kg/day and 0.59 (0.36-0.98) at 80 mg/kg/day. An increase in aspirin dose was associated with a shorter length of stay and lower medical costs. Conclusions: Low-dose aspirin may increase the risk of coronary artery abnormalities in patients with acute Kawasaki disease; however, increasing aspirin doses beyond the standard doses may not be associated with a reduction in coronary artery abnormalities. High-dose aspirin showed the potential to reduce hospital stay and medical costs without increasing complications.

Objective: To explore the use of ChatGPT by educators and students in a medical school setting. Method: This study used the public version of ChatGPT launched by OpenAI on November 30, 2022 (https://openai.com/blog/chatgpt/). We employed prompts to ask ChatGPT to 1) generate a content outline for a session on the topics of cholesterol, lipoproteins, and hyperlipidemia for medical students; 2) produce a list of learning objectives for the session; and 3) write assessment questions with and without clinical vignettes related to the identified learning objectives. We assessed the responses by ChatGPT for accuracy and reliability to determine the potential of the chatbot as an aid to educators and as a know-it-all medical information provider for students.  Results: ChatGPT can function as an aid to educators, but it is not yet suitable as a reliable information resource for educators and medical students. Conclusion: ChatGPT can be a useful tool to assist medical educators draft course and session content outlines and create assessment questions. At the same time, caution must be taken as ChatGPT is prone to providing incorrect information; expert oversight and caution are necessary to ensure the information generated is accurate and beneficial to students. Therefore, it is premature for medical students to use the current version of ChatGPT as a know-it-all information provider. In the future, medical educators should work with programming experts to explore and grow the full potential of AI in medical education.

Detection of large vessel occlusion (LVO) using machine learning on computed tomography angiography (CTA) may help stroke triage, yet applicability across varied patient and image characteristics has not been examined.  The study will examine which characteristics are important when using a convolutional neural network to identify LVO on CTA. A retrospective cohort study (November 2017 through May 2019) at a comprehensive stroke center evaluated 677 stroke-alerted patients with an LVO of the internal carotid artery, M1, or M2 (n=150), and a matching number without LVO was included. An Inception module-based network was trained for binary classification of LVO presence. Results were examined by LVO location, window settings, non-LVO findings, demographics, risk factors, presentation status, and times, interventions, and outcomes. Three hundred patients were included (48% women; median age 65). Mean+/-95% CI for cross-validation test and external validation, respectively, are area under precision-recall curve 0.871+/-0.094 and 0.742+/-0.018 and area under receiver operating characteristic curve 0.920+/-0.051 and 0.852+/-0.004. 145 true positive (TP), 5 false negative (FN), 39 false positive (FP), and 111 true negative (TN) patients were identified. Significant comparisons (P<0.05) were identified: lower window settings for misclassifications, smoking history for all FN versus 33% TP (P=0.005), and tissue plasminogen activator treatment for 41% FP versus 20% TN (P=0.017). Our LVO detection tool had high performance across patient characteristics with few exceptions. FP had pathology warranting detection, including distal occlusions. Lower window settings among misclassifications highlight the need for image quality when using machine learning for decision support.

Abstract:  Rationale and Objective Egypt currently holds a record for the most retractions in the continent of Africa according to the Retraction Watch database, and the 2nd highest of countries in the Middle East. The purpose of this study was to perform a specific analysis on retracted medical publications from Egyptian affiliations to outline or delineate specific problems and solutions.  Materials and Methods The Retraction Watch Database, Google Scholar, SCOPUS, PubMed, and journals sponsored by the Egyptian Knowledge Bank were searched for all Egypt affiliated retracted medical publications up to the date of August 31st 2022. We observed for the reason(s) for retraction, number of citations, the length of time between publication and retraction and more.  Results 68 retractions were identified that could be linked directly to a known Egyptian institution listed in the study methodology. Most retractions originated from the speciality of Obstetrics and Gynecology (n=22), followed by Anesthesia (n=7).  The top 3 reasons for retraction included unreliable results, FFP level misconduct, and duplicate publication. The number of retractions significantly increased over the years, especially in 2022. When taking into account the number of medical publications per institution, the institute with the highest rate of retractions was Mansoura University, while the lowest rate was Cairo University.  Conclusion The number of retracted medical Egyptian publications continues to increase over time, as more issues are uncovered in research coming from this region. Medical papers from this area have been the focus of investigations that have suggested that many results are statistically unlikely to have occurred.  Authors must employ a higher ethical standard in their work, while institutions must be openly collaborative with investigations and enact penalties where needed to deter future misconduct. Future studies on retracted articles should employ a methodology that considers the institutions where the studies were conducted in order to obtain a better understanding of specific problems in certain countries or regions.  Keywords: Retracted Publication, Ethics, Misconduct, Egypt, Plagiarism, RetractionWatch

An artificial intelligence (AI)-based conversational large language model (LLM) was launched in November 2022 namely, ChatGPT. Despite the wide array of potential applications of LLMs in healthcare education, research and practice, several valid concerns were raised. The current systematic review aimed to investigate the possible utility of ChatGPT and to highlight its limitations in healthcare education, research and practice. Using the PRIMSA guidelines, a systematic search was conducted to retrieve English records in PubMed/MEDLINE and Google Scholar under the term ChatGPT. Eligibility criteria included the published research or preprints of any type that discussed ChatGPT in the context of healthcare education, research and practice. A total of 280 records were identified, and following full screening, a total of 60 records were eligible for inclusion. Benefits/applications of ChatGPT were cited in 51/60 (85.0%) records with the most common being the utility in scientific writing followed by benefits in healthcare research (efficient analysis of massive datasets, code generation and rapid concise literature reviews besides utility in drug discovery and development). Benefits in healthcare practice included cost saving, documentation, personalized medicine and improved health literacy. Concerns/possible risks of ChatGPT use were expressed in 58/60 (96.7%) records with the most common being the ethical issues including the risk of bias, plagiarism, copyright issues, transparency issues, legal issues, lack of originality, incorrect responses, limited knowledge, and inaccurate citations. Despite the promising applications of ChatGPT which can result in paradigm shifts in healthcare education, research and practice, the embrace of this application should be done with extreme caution. Specific applications of ChatGPT in health education include the promising utility in personalized learning tools and shift towards more focus on critical thinking and problem-based learning. In healthcare practice, ChatGPT can be valuable for streamlining the workflow and refining personalized medicine. Saving time for the focus on experimental design and enhancing research equity and versatility are the benefits in scientific research. Regarding authorship in scientific articles, as it currently stands, ChatGPT does not qualify to be listed as an author unless the ICMJE/COPE guidelines are revised and amended. An initiative involving all stakeholders involved in healthcare education, research and practice is urgently needed to set a code of ethics and conduct on the responsible practices involving ChatGPT among other LLMs.

Pathological placental inflammation increases the risk for several adult disorders, but these mediators are also expressed under homeostatic conditions, where their contribution to adult health outcomes is unknown. Here we define an expression signature of homeostatic inflammation in the term placenta and use expression quantitative trait loci (eQTLs) to create a polygenic score (PGS) predictive of its expression. Using this PGS in the UK Biobank we carried out a phenome-wide association study, followed by mendelian randomization and identified protective, sex-dependent effects of the placental module on cardiovascular and depressive outcomes. Genes differentially regulated by intra-amniotic infection and preterm birth were also over-represented within the module. Our data support a model where disruption of placental homeostatic inflammation, following preterm birth or intra-amniotic infection, contributes to the increased risk of depression and cardiovascular disease observed in these individuals. Finally, we identify aspirin as a putative modulator of this homeostatic inflammatory signature.

Background: Nonalcoholic fatty liver disease (NAFLD) is associated with an increased risk of atherosclerotic cardiovascular disease (ASCVD) events, thus a diagnostic approach to help identify NAFLD patients at high risk is needed. In this study, we hypothesized that coronary artery calcium (CAC) screening could help stratify the risk of ASCVD events in NAFLD patients. Methods: A total of 718 NAFLD participants from Multi-Ethnic Study of Atherosclerosis (MESA) without previous cardiovascular events were followed for the occurrence of incident ASCVD. NAFLD was defined using non-enhanced computed tomography and liver/spleen attenuation ratio <1. Cox proportional hazards regression models were used to estimate hazard ratios (HR). C-statistic and net reclassification improvement were used to compare incremental contributions of CAC score when added to the clinical risk factors. Results: In multivariable analyses, CAC score was found to be independently associated with incident ASCVD (HR = 1.33, 95% CI = 1.22-1.44, p < 0.001).  The addition of CAC score to clinical risk factors increased the C-statistic from 0.677 to 0.739 (p < 0.001) and the net reclassification index was 0.721 (95% CI = 0.494-0.977). In subgroup analyses, the incremental prognostic value of CAC score was more significant in NAFLD participants with low/borderline- (<7.5%) and intermediate- (7.5-20%) 10-year ASCVD risk score.  Conclusions: The inclusion of CAC score in global risk assessment was found to significantly improve the classification of incident ASCVD events in participants with NAFLD, indicating a potential role for CAC screening in risk assessment.

Background Literature Reviews (LRs) identify, evaluate, and synthesise relevant papers to a particular research question to advance understanding and support decision making. However, LRs, especially traditional systematic reviews are slow, resource intensive, and are outdated quickly. Objective Using recent Natural Language Processing (NLP) and Unsupervised Machine Learning (UML) methods, this paper presents a tool named LiteRev that supports researchers in conducting LRs. Methods Based on the user's query, LiteRev can perform an automated search on different open-access databases and retrieve relevant metadata on the resulting papers. Papers (abstracts or full texts) are text processed and represented as a Term Frequency-Inverse Document Frequency (TF-IDF) matrix. Using dimensionality reduction (PaCMAP) and clustering (HDBSCAN) techniques, the corpus is divided into different topics described  by a list of keywords. The user can select one or several topics of interest, enter additional keywords to refine their search, or provide key papers to the research question. Based on these inputs, LiteRev performs an iterative nearest neighbours search, and suggests a list of potentially interesting papers. The user can tag the relevant ones and trigger a new search until no additional paper is suggested for screening. To assess the performance of LiteRev, we ran it in parallel to a manual LR on the burden and care for acute and early HIV infection in sub-Saharan Africa. We assessed the performance of LiteRev using True and False Predictive Values, recall and Work Saved over Sampling. Results We extracted, text processed and represented into a TF-IDF matrix 631 unique papers from PubMed. The topic modelling module identified 5 main topics and 16 topics (ranging from 13 to 98 papers) and extracted the 10 most important keywords for each. Then, based on 18 key papers, we were able to identify 2 topics of interest with 7 key papers in each of them. Finally, we ran the k-nearest neighbours module and LiteRev suggested first a list of 110 papers for screening, among which 45 papers were confirmed as relevant. From these 45 papers, LiteRev suggested 26 additional papers, out of which 8 were confirmed as relevant. At the end of the iterative process (4 iterations), 193 papers out of 613 papers in total (31.5% of the whole corpus) were suggested by LiteRev. After title/abstract screening, LiteRev identified 64 out of the 87 relevant papers (i.e., recall of 73.6%). After full text screening, LiteRev identified 42 out of the 48 relevant papers (i.e., recall of 87.5%, and Work Saved over Sampling of 56.0%). Conclusions We presented LiteRev, an automation tool that uses NLP and UML methods to streamline and accelerate LRs and to support researchers in getting quick and in-depth overviews on any topic of interest.

Background and Purpose: We aimed to describe the safety and efficacy of mechanical thrombectomy (MT) with or without intravenous thrombolysis (IVT) for patients with tandem lesions (TLs) and whether using intraprocedural antiplatelet therapy (APT) influences MTs safety with IVT treatment.<break><break>Methods: This is a sub-analysis of a pooled, international multicenter cohort of patients with acute anterior circulation TLs treated with MT. Primary outcomes included symptomatic intracranial hemorrhage (sICH) and parenchymal hematoma type 2 (PH2). Additional outcomes included hemorrhagic transformation (HT), successful reperfusion (modified Thrombolysis in Cerebral Infarction [mTICI] 2b-3), complete reperfusion (mTICI 3), favorable functional outcome (90-day modified Rankin score [mRS] 0-2), excellent functional outcome (90-day mRS 0-1), in-hospital mortality, and 90-days mortality. <break><break>Results: Of 691 patients, 599 were included (255 underwent IVT+MT and 344 MT alone). There was no difference in the risk of sICH (aOR=1.43; 95%CI:0.722.87; p=0.308), PH2 (aOR=1.14; 95%CI:0.572.28; p=0.705), and HT (aOR=0.92; 95%CI:0.541.57;p=0.751) between the IVT+MT and MT alone groups after adjusting for confounders. There was an IVT-by-intraprocedural APT interaction for sICH (p interaction=0.031). Administration of IVT was associated with an increased risk of sICH in patients who received IV-APT (aOR=3.58; 95%CI:1.1710.89;p=0.025). The IVT+MT group had higher odds of 90-days mRS 0-2 (aOR=1.76; 95%CI:1.052.94;p=0.030). The odds of successful reperfusion, complete reperfusion, 90-days mRS 0-1, in-hospital mortality, or 90-days mortality did not differ between the IVT+MT vs. MT alone groups. <break><break>Conclusion: Our study showed that the combination of IVT with MT for TL did not increase the overall risk of sICH, PH2, or overall HT independently of the cervical revascularization technique used. However, intraprocedural IV-ATP during acute stent implantation might be associated with an increased risk of sICH in patients who received IVT prior to MT. Importantly, IVT+MT treatment was associated with a higher rate of favorable functional outcome at 90 days.

Objective: This study aims to evaluate the impact of a primary care nurse-practitioner-led clinic model piloted in British Columbia (Canada) on patients' health and care experience. Design: The study relies on a quasi-experimental longitudinal design based on a pre-and-post survey of patients receiving care in NP-Led clinics. The pre-rostering survey (T0) was focused on patients' health status and care experiences preceding being rostered to the NP clinic. One year later, patients were asked to complete a similar survey (T1) focused on the care experiences with the NP clinic. Setting: To solve recurring problems related to poor primary care accessibility, British Columbia opened four pilot NP-led clinics in 2020. Each clinic has the equivalent of approximately six full-time NPs, four other clinicians plus support staff. Clinics are located in four cities ranging from core urban to peri rural. Participants: Recruitment was conducted by the clinic's clerical staff or by their care provider. A total of 437 usable T0 surveys and 254 matched and usable T1 surveys were collected. Primary outcome measures: The survey instrument was focused on five core dimensions of patients' primary care experience (accessibility, continuity, comprehensiveness, responsiveness, and outcomes of care) as well as on the SF-12 Short-form Health Survey. Results: Scores for all dimensions of patients' primary care experience increased significantly: Accessibility (T0=5.9, T1=7.9, p<0.000), Continuity (T0=5.5, T1=8.8, p<0.000), Comprehensiveness (T0=5.6, T1=8.4, p<0.000), Responsiveness (T0=7.2, T1=9.5, p<0.000), Outcomes of care (T0=5.0, T1=8.3, p<0.000). SF-12 Physical health T-scores also rose significantly (T0=44.8, T1=47.6, p<0.000) but no changes we found in the mental health T scores (T0=45.8, T1=46.3 p=0.709). Conclusions: Our results suggest that the NP-Led primary care model studied here likely constitutes an effective approach to improve primary care accessibility and quality.

Background: The transition from fetal to neonatal circulation is a complex physiological phenomenon, influenced by umbilical cord clamping and lung aeration, which triggers an increase in pulmonary blood flow and left ventricular preload. Although clinical evidence suggests that delayed cord clamping (DCC) prevents complications of haemodynamic instability, such as cerebrovascular injury, the cardiovascular consequences of DCC have not been investigated yet in humans. Methods: Echocardiography was performed in 46 term vigorous infants before DCC, immediately after DCC, and at 5 minutes of life. Pulsed-wave Doppler-derived cardiac output and the pulmonary artery acceleration time indexed to the right ventricle ejection time, as a proxy of right ventricular afterload, were obtained. As markers of pre- and afterload fluctuations, the myocardial performance indexes and the velocities of the tricuspid and mitral valve annuli were determined with tissue Doppler imaging. Heart rate was derived from Doppler imaging and obtained throughout the assessments. Echocardiographic parameters were compared across the three timepoints using repeated measures ANOVA or Friedman's test. Results: DCC occurred at a median of 65 seconds (interquartile range 60-70). Left ventricular output increased throughout the first minutes of life (mean(SD): 222.4(32.5) mL/Kg/min before CC vs. 239.7(33.6) mL/Kg/min at 5 minutes, P=0.01), while right ventricular output dropped after CC (306.5(48.2) mL/Kg/min before CC vs. 272.8(55.5) mL/Kg/min immediately after CC, P=0.001). Right ventricular afterload rose after CC, decreasing in the following minutes. The tissue Doppler measurements showed that the loading conditions of both ventricles were transiently impaired by CC, recovering at 5 minutes. The heart rate progressively decreased after birth, following a linear trend temporarily disrupted by CC. Forward stepwise regression indicated that the variation in left ventricular output across the CC was directly correlated to the fluctuation of left ventricular preload over the same period (P=0.03).  Conclusion: This study unveils the cardiovascular consequences of DCC in term vigorous infants and offers insight into the haemodynamic transition from fetal to neonatal circulation in humans. Strategies that aim to enhance left ventricular preload before CC, such as initiating ventilation with an intact umbilical cord in apneic infants, may prevent complications of perinatal cardiovascular imbalance.

Background Anthracycline-induced cardiotoxicity has a variable incidence, and the development of left ventricular dysfunction is preceded by elevations in cardiac troponin concentrations. Beta-adrenergic receptor blocker and renin-angiotensin-system inhibitor therapies have been associated with modest cardioprotective effects in unselected patients receiving anthracycline chemotherapy. Methods In a multicenter prospective randomized open label blinded endpoint trial, patients with breast cancer and non-Hodgkin lymphoma receiving anthracycline chemotherapy underwent serial high-sensitivity cardiac troponin testing and cardiac magnetic resonance imaging before and 6 months after anthracycline treatment. Patients at high risk of cardiotoxicity (cardiac troponin I concentrations in the upper tertile during chemotherapy) were randomized to standard of care plus cardioprotection (combination carvedilol and candesartan therapy) or standard of care alone. The primary outcome was adjusted change in left ventricular ejection fraction (LVEF) at 6 months. In low-risk non-randomized patients with cardiac troponin I concentrations in the lower two tertiles, we hypothesised the absence of a 6-month change in LVEF (±2%).  Results Between October 2017 and June 2021, 175 patients (mean age 53 years; 87% female; 71% breast cancer) were recruited. Patients randomized to cardioprotection (n=29) or standard care (n=28) had LVEFs of 69.4±7.4% and 69.1±6.1% at baseline and 65.7±6.6% and 64.9±5.9% 6 months after completion of chemotherapy. After adjusting for age, pre-treatment LVEF and planned anthracycline dose, the estimated mean difference in 6-month LVEF between cardioprotection and standard care groups was -0.4% (95% CI, -3.59 to 2.85%; P=0.82). In low-risk non-randomized patients, baseline and 6-month LVEFs were 69.3±5.7% and 66.4±6.3% respectively: estimated mean difference, 2.9% (95% CI, 1.45 to 4.28%; P<0.001).  Conclusions Combination candesartan and carvedilol therapy had no demonstrable cardioprotective effect in patients receiving anthracycline-based chemotherapy with high-risk on-treatment cardiac troponin I concentrations. Low-risk non-randomized patients had similar declines in LVEF casting doubt over the utility of routine cardiac troponin monitoring. Furthermore, the modest declines in LVEF suggest that the value and clinical impact of early cardioprotection therapy needs to be better defined in patients receiving high dose anthracycline regimes.

Background and purpose: Guidelines recommend patients with high-risk TIAs and minor stroke presenting within 1-3 days from onset be offered dual antiplatelet therapy (DAPT). There is little data on real-world adherence to these recommendations. We evaluated the appropriateness of DAPT use in TIA and stroke patients in a prospective Database. Methods: The Qatar Stroke Database began enrollment of patients with TIAs and acute stroke in 2014 and currently has ~ 16,000 patients. For this study we evaluated the rates of guideline-adherent use of antiplatelet treatment at the time of discharge in patients with TIAs and stroke. TIAs were considered high-risk with ABCD2 score of ? 4 and minor stroke was defined as NIHSS ? 3. Patient demographics, clinical features, risk factors, previous medications, imaging and laboratory investigations, final diagnosis, discharge medications, and discharge and 90-day modified Rankin Scale (mRS) were analyzed. Results: After excluding patients with ICH, mimics and rare secondary causes, 8082 patients available for final analysis (TIAs: 1357;stroke 6725). In high-risk TIAs, 282 of 666 (42.3%) patients were discharged on DAPT. In patients with minor stroke, 1207 of 3572 (33.8%) patients were discharged on DAPT. DAPT was inappropriately offered to 238 of 691 (34.4%) of low-risk TIAs and 809 of 3153 (25.7%) of non-minor stroke patients.  Conclusions: This large database of prospectively collected patients with TIAs and stroke shows that, unfortunately, despite several guidelines, a large majority of patients with TIAs and stroke are receiving inappropriate antiplatelet treatment at discharge from hospital. This requires urgent attention and further investigation.

A recent randomized clinical trial, INCEPTION, reported in patients with refractory out-of-hospital cardiac arrest, extracorporeal CPR (eCPR) and conventional CPR (cCPR) had similar effects on survival with a favorable neurologic outcome. The current study examines if a Bayesian perspective provides additional quantative insights. Depending on the prior selected, the Bayesian approach for the INCEPTION intentionto treat (ITT) analysis shows an equivalence probability between 13.4 - 16.8% (defined as 1 / 1.1 < odds ratio (OR) < 1.1). The probability of clinical superiority with eCPR ranges from 65.7 - 77.0 % (defined as OR > 1.1). A similar analyses using INCEPTION per protocol (PP) data shows an equivalence probability between 4.7 - 20.2% with reduced probabilities of clinical superiority not exceeding 25%. It is concluded that a Bayesian perspective allows considerable additional quantative insights into the trial analysis and interpretation. The non-negligible probabilities of increased survival, or even harm, with their considerable residual uncertainties, suggests that additional studies are required before concluding that eCPR and cCPR have similar average survival effects.

Background: The progression of chronic kidney disease (CKD) is higher in Black than in White Americans but studies have mainly focused on racial differences within advanced CKD. We evaluated CKD progression in Black and White participants over 20 years and the contribution of cardiovascular conventional and non-traditional risk factors to racial disparities in CKD progression. Methods: This study was based on 2,175 Black and 2,207 White adults in the Coronary Artery Risk Development in Young Adults (CARDIA) study. Both estimated glomerular filtration rate (eGFR) and urinary albumin-to-creatinine ratio (UACR) were measured at study year 10 (age 27-41y) and every five years for 20 years. The outcome was CKD progression through No CKD into Low, Moderate, High, or Very High Risk that was based on categories of eGFR and UACR in combination. The association between race and CKD progression as well as the contribution of risk factors to racial differences were assessed in multivariable-adjusted Cox proportional hazards models.  Results: Black participants had higher CKD transition probabilities than White participants and more prevalent risk factors during the 20-year period studied. HRs for CKD transition for Black (vs White participants) were 1.38 from No CKD into ≥ Low Risk, 2.25 from ≤ Low Risk into ≥ Moderate Risk, and 4.49 for from ≤ Moderate Risk into ≥ High Risk. Racial differences in CKD progression from No CKD into ≥ Low Risk were primarily explained by forced vital capacity (FVC) (54.8%), hypertension (30.9%), and obesity (20.8%). Similar findings were observed for the race difference in transition from ≤ Low Risk into ≥ Moderate Risk, but little of the race difference in transition ≤ Moderate Risk into ≥ High Risk was explained. Conclusions: In this longitudinal study, Black compared to White participants had a higher risk of CKD progression, and this discrepancy may be partly explained by conventional and non-traditional factors.

Background. People undergoing revascularization for symptomatic peripheral artery disease (PAD) have a high incidence of major limb amputation in the year following their surgical procedure. The incidence of limb amputation is particularly high in patients from racial and ethnic minority groups. The purpose of our study was to investigate the role of sub-optimal prescription of preoperative antiplatelets and statins in producing disparities in risk of major amputation following revascularization for symptomatic PAD.  Methods. We used data from adult (≥18 years old) patients in the Vascular Quality Initiative (VQI) registry who underwent a revascularization procedure from 2011-2018. Patients were categorized as non-Hispanic Black, non-Hispanic White, and Hispanic. We estimated the crude probability of a patient being prescribed a preoperative antiplatelet and preoperative statin. We calculated one year risk incidence of amputation by prescription groups and by race/ethnicity. We estimated the amputation risk difference between race/ethnicity groups (the proportion of disparity) that could be eliminated under a hypothetical intervention where a pre-operative antiplatelet and statin was provided to all patients.  Results. Across 100,579 revascularizations recorded in the Vascular Quality Initiative, a vascular procedure-based registry in the United States and Canada, 1-year risk of amputation was 2.5% (95% CI: 2.4%,2.6%) in White patients, 5.3% (4.9%,5.6%) in Black patients and 5.3% (4.7%,5.9%) in Hispanic patients. Black (57.5%) and Hispanic patients (58.7%) were only slightly less likely than White patients (60.9%) to receive recommended antiplatelet and statin therapy prior to their procedures. However, the effect of antiplatelets and statins was greater in Black and Hispanic patients such that, had all patients received the appropriate guideline recommended medications, the estimated risk difference comparing Black to White patients would have reduced by 8.9% (-2.9%,21.9%) and the risk difference comparing Hispanic to White patients would have been reduced by 17.6% (-0.7%,38.6%).  Conclusions. Even though guideline-based care appeared evenly distributed by race/ethnicity, increasing access to such care may still decrease health care disparities in major limb amputation.

Background: In 2014, Uganda launched the National Male Involvement Strategy in Maternal and Child Health. In 2020, the District Health Management Information System report for Lamwo district, where Palabek Refugee Settlement is located, indicated a 10% male involvement in antenatal care (ANC). We investigated determinants of male involvement in ANC in Palabek Refugee Settlement to inform programs on improvement of male involvement in ANC in a refugee setting. Methodology: We conducted a community-based cross-sectional analytical study among a proportionate sample of mothers in Palabek Refugee Settlement from October-December 2021. Using a standardized questionnaire, we collected information on demographics and the constructs of the socio-ecological model where consent was given. We summarized data in tables and figures. We used Pearson chi-square test to determine significance of independent variables at bivariate level. A multivariable logistic regression model was run for all variables found significant at bivariate analysis to determine association between the different independent variables and male involvement in ANC.  Results: We interviewed 423 mothers. The mean age of their male partners was 31 years, SD 7. Eighty-one percent (343/423) of male partners had formal education, with 13% (55/423) having a source of income and 61% (257/423) having access to ANC information during their pregnancy. The level of male involvement in ANC in Palabek Refugee Settlement was 39% (164/423). Male involvement in ANC was positively associated with access to information on ANC (AOR 3.0; 95%Cl: 1.7-5.4) and frequent couple discussion on ANC (AOR 10.1; 95%Cl: 5.6-18.0). However, it was negatively associated with distance < 3km to the health facility (AOR 0.6 ;95%Cl: 0.4-1.0).           Conclusions: Approximately one in three male partners in Palabek Refugee Settlement were involved in ANC. Male partners who had access to information during ANC and those who had frequent discussions were more likely to get involved in ANC. Men who lived ≥3 kilometres from the health facility were less likely to be involved in ANC. We recommend intensified awareness creation on importance of male involvement in ANC and implementation of integrated community outreaches to reduce distance to the health facility. Key words: Male involvement, antenatal care, Palabek Refugee Settlement, Northern Uganda. Word count: 340 Abstract, 4201 main text

Background: To characterize interferences between Streptococcus pneumoniae and SARS-CoV-2 we investigated the longitudinal patterns of viral infection and pneumococcal carriage in households infected with SARS-CoV-2.  Methods: SARS-CoV-2 and pneumococcus were detected with quantitative molecular methods in saliva from members of eighty participating households. Samples were collected between October 2020 and January 2021 from n=197 adults and n=118 children of which n=176 adults and n=98 children had a complete set of ten samples collected within 42 days since enrolment. Time-dependent Cox models were used to evaluate the associations between SARS-CoV-2 and pneumococcal carriage.  Results: In the entire cohort, cumulative pneumococcal carriage and SARS-CoV-2 infection rates were 58% and 65%, respectively. Pneumococcal abundances were associated with an increased risk of SARS-CoV-2 infection (HR 1.14, 95% CI, 1.01-1.29, P=0.04) and delayed clearance of SARS-CoV-2 infection (HR 0.90, 95% CI, 0.82-0.99, P=0.03). Elevated viral loads were observed among pneumococcal carriers and individuals with high overall bacterial 16S abundances, however, there were no longitudinal differences in viral loads in linear mixed-effects models. Individuals with high 16S abundances displayed delayed viral clearance (HR 0.65, 95% CI 0.55-0.78, P<0.0001).  Conclusions: Although we found insufficient evidence for a strong impact of SARS-CoV-2 infection on pneumococcal carriage. Results from the current study suggest that pneumococcal carriers may have an increased risk of SARS-CoV-2 infection and high pneumococcal abundances and 16S abundances may be associated with elevated viral loads and delayed clearance of SARS-CoV-2 infection.

Age-associated B cells (ABCs) accumulate with age, as well as in individuals with a range of immunological dyscrasias. These include patients with cancer treated with immune checkpoint blockade and patients with inborn errors of immunity. In this study, we sought to determine whether ABCs found in all these conditions are similar, and whether they enhance or detract from the response to COVID-19 vaccination. We use single cell RNA sequencing to show that ABCs arising from distinct aetiologies have common transcriptional profiles and may be subdivided according to the expression of genes associated with different immune functions, such as the autoimmune regulator (AIRE). Next, we perform detailed longitudinal profiling of the COVID-19 vaccination response in patients and controls. We show that high pre-vaccination ABC frequency correlates with decreased levels of antigen-specific memory B cells, and reduced magnitude and longevity of neutralising capacity against SARS-CoV-2 virus. Potentially contributing to this, ABCs express high levels of the inhibitory FcγRIIB receptor and are distinctive in their ability to bind immune complexes. This could contribute to diminished vaccine responses either directly as result of inhibitory signalling or indirectly via enhanced clearance of immune complexed-antigen. Expansion of ABCs may therefore serve as a biomarker identifying individuals at risk of a suboptimal response to COVID-19 vaccination.

We aimed to assess the prevalence of asymptomatic cases of monkeypox virus (MPXV) infection among gay, bisexual, and other men who have sex with men and trans women (TW), using a self-sampling strategy. Anal and pharyngeal swabs were tested by MPXV real-time PCR and positive samples inoculated into Vero E6 cells, which were subsequently checked for cytopathic effect (CPE).  Seven out 113 participants were MPXV positive (6.19% (95% CI: 1.75%-10.64%)). Five tested positive in pharyngeal swabs, one in anal swab and one in both. Six did not present symptoms recognized as MPXV infection. Three samples were positive for CPE, and showed anti-vaccinia pAb staining by FACS and confocal microscopy.  We describe Mpox cases that remain undiagnosed and show reproductive virus despite low viral loads and who might be able to infect others. Restricting testing to individuals reporting Mpox symptoms may not be enough to contain outbreaks.

Background: Clinicopathological features are used for detection of diseases. Early detection of cancer can be significance for understanding the behavior of disease.  Results: We developed a tool to observe stomach adenocarcinoma in reference of blood-lipid profile. Background of the tool is based on the study made on RNAseq expression analysis of stomach adenocarcinoma. Raw data for study was collected as gene-expression profile from population of cancer-vs-normal. A series of studies performed including: differential gene expression analysis, plasma proteome mapping, extraction of gene-signature enriched with LSTM system model, AI-guided simulation of systems model of gene network, and AI-guided mapping with blood lipid profile to develop R-Shiny web-application.  Conclusion: EarlyDetect, is freely available at https://csir-icmr.shinyapps.io/EarlyDetect/. The tool can be utilized for (i) virtual observation of impact of different combinations of lipid profile in cancer progression; (ii) early detection of cancer state for new comer patients.

Aims: Type 1 diabetes (T1D) results from an autoimmune attack of the pancreatic beta cells that progresses to dysglycemia and symptomatic hyperglycemia. Current biomarkers to track this evolution are limited, with development of islet autoantibodies marking the onset of autoimmunity and metabolic tests used to detect dysglycemia. Therefore, additional biomarkers are needed to better track disease initiation and progression. Multiple clinical studies have used proteomics to identify biomarker candidates. However, most of the studies were limited to the initial candidate identification, which needs to be further validated and have assays developed for clinical use. Here we curate these studies to help prioritize biomarker candidates for validation studies and to obtain a broader view of processes regulated during disease development.  Methods: This systematic review was registered with Open Science Framework (DOI 10.17605/OSF.IO/N8TSA). Using PRISMA guidelines, we conducted a systematic search of proteomics studies of T1D in the PubMed to identify putative protein biomarkers of the disease. Studies that performed mass spectrometry-based untargeted/targeted proteomic analysis of human serum/plasma of control, pre-seroconversion, post-seroconversion, and/or T1D-diagnosed subjects were included. For unbiased screening, 3 reviewers screened all the articles independently using the pre-determined criteria. Results: A total of 13 studies met our inclusion criteria, resulting in the identification of 251 unique proteins, with 27 (11%) being identified across 3 or more studies. The circulating protein biomarkers were found to be enriched in complement, lipid metabolism, and immune response pathways, all of which are found to be dysregulated in different phases of T1D development. We found a subset of 3 proteins (C3, KNG1 & CFAH), 6 proteins (C3, C4A, APOA4, C4B, A2AP & BTD) and 7 proteins (C3, CLUS, APOA4, C6, A2AP, C1R & CFAI) have consistent regulation between multiple studies in samples from individuals at pre-seroconversion, post-seroconversion and post-diagnosis compared to controls, respectively, making them strong candidates for clinical assay development. Conclusions: Biomarkers analyzed in this systematic review highlight alterations in specific biological processes in T1D, including complement, lipid metabolism, and immune response pathways, and may have potential for further use in the clinic as prognostic or diagnostic assays.

Background: Per- and polyfluoroalkyl substances (PFAS) are a growing class of manufactured chemical compounds found in a variety of consumer products. PFAS have become ubiquitous in the environment and were found in many humans sampled in the United States (U.S.). Yet, significant gaps in understanding statewide level exposures to PFAS remain.  Objective: The goals of this study are to establish a baseline of exposure at the state level by measuring PFAS serum levels among a representative sample of Wisconsin residents and compare to United States National Health and Nutrition Examination Survey (NHANES). Methods: The study sample included 605 adults (18+ years of age) selected from the 2014-2016 sample of the Survey of the Health of Wisconsin (SHOW). Thirty-eight PFAS serum concentrations were measured using high-pressure liquid chromatography coupled with tandem mass spectrometric detection (HPLC-MS/MS) and geometric means presented. Weighted geometric mean serum values of eight PFAS analytes from SHOW were compared to U.S. national levels from the NHANES 2015-2016 sample (PFOS, PFOA, PFNA, PFHxS, PFHpS, PFDA, PFUnDA), and the 2017-2018 sample for Me-PFOSA, PFHPS using the Wilcoxon rank-sum test.  Results: Over 96% of SHOW participants had positive results for PFOS, PFHxS, PFHpS, PFDA, PFNA, and PFOA. In general, SHOW participants had lower serum levels across all PFAS when compared to NHANES. Serum levels increased with age and were higher among males and whites. These trends were seen in NHANES, except non-whites had higher PFAS levels at higher percentiles.  Significance: Wisconsin residents may have a lower overall body burden of some PFAS compounds compared to those seen by a nationally representative sample. Additional testing and characterization may be needed in Wisconsin, particularly among non-whites and low socioeconomic status, for which the SHOW sample had less representation compared to NHANES.

Background: Patients with Parkinson's disease undergo a loss of melanized neurons in substantia nigra pars compacta (SNc) and locus coeruleus (LC). There are very few in vivo studies of LC pathology in Parkinson's disease with magnetic resonance imaging (MRI). Existing studies have used varying methodologies, and reproducibility has not been established for any approach.  Methods: Two cohorts, discovery and validation, were recruited from the Emory Movement Disorders Clinic and scanned on two different MRI scanners. In cohort 1, imaging data from 19 controls and 22 Parkinson's disease patients were acquired with a Siemens Trio 3 Tesla scanner using a 2D gradient echo sequence with magnetization transfer preparation pulse. Cohort 2 consisted of 33 controls and 39 Parkinson's disease patients who were scanned on a Siemens Prisma 3 Tesla scanner with a similar imaging protocol. LC and SNc volumes were segmented in both cohorts.  Results:  SNc volume (Cohort 1: p=0.0148; Cohort 2: p=0.0011) and LC volume (Cohort 1: p=0.0412; Cohort 2: p=0.0056) were significantly reduced in the Parkinson's disease group as compared to controls in both cohorts.  Conclusion: SNc volume and LC volume were significantly reduced in Parkinson's disease compared to controls in both cohorts. This imaging approach robustly detects Parkinson's disease effects on these structures, indicating that it is a promising marker for neurodegenerative neuromelanin loss.

Our previous research demonstrated that genetic distance (GD) on effective mutation (EM) sites can be used to evaluate vaccine effectiveness (VE) in silico in real time. This study further investigates the relationship between VE and GD on antigenic sites (AS) and identifies key amino acid sites related to vaccine protection against influenza A/H1N1pdm09 and A/H3N2 between 2009 and 2019 flu seasons. We found that not any AS on hemagglutinin (HA) and neuraminidase (NA) may cause a decrease in VE, rather, GD on the intersection set of EM and AS is highly predictive of influenza VE. The integrated GD of HA and NA can explain up to 87.8% of VE variations for H3N2. Significant improvement is also found for VE prediction for pH1N1. Accurate prediction of influenza VE before vaccine deployment may facilitate reverse vaccinology to optimize vaccine antigen design and facilitate government preparedness of epidemics.

Objective: To investigate the diagnostic and prognostic role of gastric fluid DNA (gfDNA) in gasric cancer (GC) patients and controls submitted to upper digestive endoscopy. Design: The concentration of gfDNA was evaluated in 941 samples, including subjects with normal gastric mucosa (n = 10), peptic diseases (n = 596), pre-neoplastic conditions (n = 99), and cancer (n = 236). gfDNA levels were evaluated according to age, gender, BMI, gastric fluids pH, use of proton-pump inhibitors, GC tumor subtypes, histological grades, clinical stages, and disease progression/outcome. Results: In the non-cancer group, we observed that gfDNA levels are increased in women as compared to men (p=7.44e-4). Remarkably, gfDNA levels are increased in GC patients as compared to non-GC (normal + peptic diseases, p=5.67e-13) and in GC versus pre-neoplastic disease (p=1.53e-6). Similar differences were also seen when more advanced tumors (T3) were compared to early stages (T2 and below) (p=5.97-4). Moreover, our results suggest the prognostic value of gfDNA as GC-patients with higher gfDNA concentrations (<1.28ng/microliter) had increased infiltration of immune cells in the tumor (p=1.06e-3), which parallels with better disease-free survival (p= 0.014). Conclusion: These findings highlight the significance of collecting and studying stomach fluids from gastric cancer patients and reveals the potential impact of this approach as well as its diagnostic and prognostic value for disease management.

Because of the large number of infected individuals, an estimate of the future burdens of the long-term consequences of SARS-CoV-2 infection is needed. This systematic review examined associations between SARS-CoV-2 infection and incidence of categories of and selected chronic conditions, by age and severity of infection (inpatient vs. outpatient/mixed care). MEDLINE and EMBASE were searched (Jan 1, 2020 to Oct 4, 2022) and reference lists scanned. We included observational studies from high-income OECD countries with a control group adjusting for sex and comorbidities. Identified records underwent a two-stage screening process. Two reviewers screened 50% of titles/abstracts, after which DistillerAI acted as second reviewer. Two reviewers then screened the full texts of stage one selections. One reviewer extracted data and assessed risk of bias; results were verified by another. Random-effects meta-analysis estimated pooled hazard ratios (HR). GRADE assessed certainty of the evidence. Twenty-five studies were included. Among the outpatient/mixed SARS-CoV-2 care group, there is high certainty of a small-to-moderate increase (i.e., HR 1.26 to 1.99) among adults ≥65 years of any cardiovascular condition, and of little-to-no difference (i.e., HR 0.75 to 1.25) in anxiety disorders for individuals <18, 18-64, and ≥65 years old. Among 18-64 and ≥65 year-olds receiving outpatient/mixed care there are probably (moderate certainty) large increases (i.e., HR ≥2.0) in encephalopathy, interstitial lung disease, and respiratory failure. After SARS-CoV-2 infection, there is probably an increased risk of diagnoses for some chronic conditions; whether the magnitude of risk will remain stable into the future is uncertain.







Background Accurate recognition and recording of intellectual disability in those who are admitted to general hospitals is necessary for making reasonable adjustments, ensuring equitable access, and monitoring quality of care. In this study we determined the rate of recording of intellectual disability in those with the condition who were admitted to hospital, and factors associated with the condition being unrecorded.Methods and Findings Retrospective cohort study using two linked datasets of routinely collected clinical data. We identified adults with diagnosed intellectual disability in a large secondary mental healthcare database and used general hospital records to investigate recording of intellectual disability when people were admitted to general hospitals between 2006 and 2019. Trends over time and factors associated with intellectual disability being unrecorded were investigated. We obtained data on 2,477 adults with intellectual disability who were admitted to a general hospital in England at least once during the study period (total number of admissions=27,314; median number of admissions=5). People with intellectual disability were accurately recorded as having the condition during 2.9% (95%CI 2.7-3.1%) of their admissions. Broadening the criteria to include a non-specific code of learning difficulty increased recording to 27.7% (95%CI 27.2-28.3%) of all admissions. Having a mild intellectual disability and being married were associated with increased odds of the intellectual disability being unrecorded in hospital records. We had no measure of quality of hospital care received and could not relate this to the presence or absence of a record of intellectual disability in the patient record.Conclusions Recognition and recording of intellectual disability in adults admitted to English general hospitals needs to be improved. Staff awareness training, screening at the point of admission, and data sharing between health and social care services could improve care for people with intellectual disability.

This study aims to determine the approximate number of hospitalizations of persons without family and the medical challenges they encounter in hospitals across Japan. Self-administered questionnaires were mailed to 4,000 randomly selected hospitals nationwide to investigate the actual conditions and problems, decision-making processes, and use of the government-recommended Guidelines for the hospitalization of, and decision-making support for, persons without family. To identify the characteristics of each region and hospital function, chi-square tests were used to make separate group comparisons by hospital location and type. Responses were received from 1,271 hospitals (31.2% response rate), of which 952 hospitals provided information regarding the number of admissions of persons without family. The mean (SD) and median number of hospitalizations (approximate number per year) of patients without family was 16 (79) and 5, respectively. Approximately 70% of the target hospitals had allowed the hospitalization of a person without family. The most common difficulties encountered during the hospitalization were collecting emergency contact information, decision-making related to medical care, and discharge support. In the absence of family members and surrogates, the medical team undertook the decision-making process, which was commonly performed according to manuals and guidelines and by consulting an ethics committee. Regarding the use of the government-recommended Guidelines, approximately 70% of the hospitals that were aware of these Guidelines responded that they had never taken any action based on these Guidelines, with significant differences by region and hospital type. To solve the problems related to the hospitalization of persons without family, the public should be made aware of these Guidelines, and measures should be undertaken to make clinical ethics consultation a sustainable activity within hospitals.





Objective To describe a set of tumor characteristics, prognosis and course of pregnancy in patients diagnosed with pregnancy-associated breast cancer (PABC).Methods Retrospective cohort study of PABC young women. The histological profile, survival and pregnancy outcomes were assessed. Nonparametric tests, Fisher’s exact test, Kaplan-Meier method, Cox regression and multivariate logistic regression were used for statistical analyses.Results We assessed 16 PABC patients. All women self-palpated a breast mass, the women ≤ 35 years of age were diagnosed with unfavorable characteristics: advanced stage (88.8%), positive clinically lymph nodes (100%), high grade (55.5%), ER-negative (77.8%) and high-risk Nottingham prognostic index (66.7%).Seven deaths were observed with a median follow-up for overall survival (OS) of 64.5 months (range: 15-90). The 5-year OS rates were worse for patients with pathological lymph nodes > 4 (25%; p = 0.001) and with ER-negative disease (50%; p = 0.646).In our multivariate analysis, the nodal involvement was the only predictor associated to a worse OS (hazard ratio = 1.4, 90% confidence interval [CI]: 1.14 to 1.8). The following risk factors could influence in the risk of a preterm birth: mother’s older age, gestational age at diagnosis and the chemotherapy during pregnancy, but their adjusted ORs of .61 (90% CI: 0.34 to 1), .80 (90% CI: 0.66 to 0.9) and .01 (90% CI: 0.00 to 0.9), respectively did not support statistically such an effect. Most cases of cases (77.7%) exposed to chemotherapy during pregnancy got a live term birth.Conclusion Our findings described a more aggressive histological profile for youngest pregnant women coupled the delayed diagnosis might explain the high-risk of death. Simultaneous management of breast cancer and pregnancy was feasible.



Whole genome sequence analysis of the Mycobacterium tuberculosis (Mtb) isolates show correlation to their drug resistance phenotype which may also reflect in their global metabolome. In this report, clinical Mtb isolates (S1, S4, S5, S6, S7, S10) harvested from the sputum of tuberculosis patients were characterized using drug sensitive test (DST), electron microscope, whole genome sequencing (WGS) and metabolomics. Majority of these Mtb isolates showed similar size (length: 1.0–3.2 μm; width: 0.32–0.52 μm) to the H37Rv Mtb strain whereas significant variations were observed in their growth kinetics, WGS and metabolome profiles. In-silico drug resistance prediction, from the WGS data (single-nulceotide polymorphisms (SNP) pattern) of these Mtb isolates showed resistance to tuberculosis drugs and matched with DST results. Differences in the genes involved in stress response, pathogenicity, drug efflux pumps were observed between isolates but genes of the central carbon metabolic pathways and amino acid metabolism were conserved. Gas chromatography and mass spectrometry (GC-MS) based metabolite profiling of these clinical isolates identified 291 metabolites involved in various metabolic pathways and a sub set of these metabolites (glutamic acid, aspartic acid and serine) contributed to the drug resistance patterns. These clinical Mtb isolates could be useful as alternate reagent for understanding host pathogen interaction and the pipeline used for WGS analysis could be used to predict drug resistance pattern of new Mtb isolates.



Background and Aims One of the most important complications of heart transplantation is organ rejection, which is diagnosed on endomyocardial biopsies by pathologists. Computer-based systems could assist in the diagnostic process and potentially improve reproducibility. Here, we evaluated the feasibility of using deep learning in predicting the degree of cellular rejection from pathology slides as defined by the International Society for Heart and Lung Transplantation (ISHLT) grading system.Methods We collected 1079 histopathology slides from 325 patients from three transplant centers in Germany. We trained an attention-based deep neural network to predict rejection in the primary cohort and evaluated its performance using cross validation and by deploying it to three cohorts.Results For binary prediction (rejection yes/no) the mean Area Under the Receiver Operating Curve (AUROC) was 0.849 in the cross-validated experiment and 0.734, 0.729 and 0.716 in external validation cohorts. For a prediction of the ISHLT grade (0R, 1R, 2/3R), AUROCs were 0.835, 0.633 and 0.905 in the cross-validated experiment and 0.764, 0.597, 0.913, and 0.631, 0.633, 0.682, and 0.722, 0.601, 0.805 in the validation cohorts, respectively. The predictions of the AI model were interpretable by human experts and highlighted plausible morphological patterns.Conclusions We conclude that artificial intelligence can detect patterns of cellular transplant rejection in routine pathology, even when trained on small cohorts.

Neuroscience has contributed to uncover the mechanisms underpinning substance use disorders (SUD). The next frontier is to leverage these mechanisms as active ingredients to create more effective interventions for SUD. Recent large-scale cohort studies are generating multiple levels of neuroscience-based information with potential to inform the development and refinement of future preventive strategies. However, there is still no available well-recognized frameworks to guide the integration of these complex datasets into prevention trial protocols. The Research Domain Criteria (RDoC) provides a neuroscience-based multi-system framework that is well suited to facilitate translation of neurobiological mechanisms into behavioural domains amenable to preventative interventions. We propose a novel RDoC-based framework for prevention science that organizes and advances the integration of technologies and findings from neuroscience into the refinement of current and construction of future preventive and early interventions. This neuroscience-informed framework categorizes addiction risk factors within the dysfunction of the five major RDoC constructs (Negative Valence Systems, Positive Valence Systems, Cognitive Systems, Arousal and Regulatory Systems, and Social Processes). We adapted the framework for the existing preventive interventions and categorized their components using RDoC constructs. From a systematic review of randomized controlled trials using a person-centered drug/alcohol preventive approach for adolescents (13-18 years), we identified 98 trials on 37 preventive interventions. We categorized them within this framework based on their potential target(s). By using this neuroscience-informed framework, distinct neurocognitive trajectories which have been recognized as precursors or risk factors for SUDs, can be targeted, and more importantly, the change processes can be evaluated to inform causal hypotheses. This framework can also inform individualized assessment, intervention development and outcome measurement in preventive interventions.

Objectives In Rwanda, rates of malnutrition remain high in rural areas where residents consume a primarily starch-based, low variety diet. Nutrition-sensitive agricultural interventions using kitchen gardens have been effective in addressing low diet diversity in similar populations. This study’s objective was to develop a kitchen garden and nutrition education intervention aimed at sustainably increasing diet diversity and food security at the household-level.Design A mixed methods community-level study, with a sixteen-week nutrition-sensitive agricultural intervention including nutrition education was conducted. Household diet diversity scores and household hunger scores were calculated at baseline, post-intervention and one-year follow-up.Setting The intervention was conducted in a rural Rwandan community in the Northern Province.Participants Stratified purposeful sampling techniques were used to select women participants representing forty-two households.Results Household diet diversity scores increased over time from pre-intervention to six months post-intervention and one-year post-intervention. The magnitude of the change was similar in all stratified groups (2.3x at 6 months and 2.9x at 1 year). Households whose main source of income was working for other farmers, reported a significantly lower diet diversity score than those households receiving income from sources [t(40) = -2.108, p=0.041]. Among those households not consuming protein and vitamin-A rich food groups at baseline, all reported consuming foods from these food groups post-intervention. There were no significant changes in household hunger scores.Conclusions Collaborative community-based nutrition-sensitive agricultural interventions using kitchen gardens, can increase household diet diversity, which may encourage sustained change in dietary patterns for nutritional adequacy in low-income rural Rwandan populations.



Multiple randomized controlled trials, each comparing a subset of competing interventions, can be synthesized by means of a network meta-analysis to estimate relative treatment effects between all interventions in the evidence base. Often there is an interest in estimating the relative treatment effects regarding time-to-event outcomes. Cancer treatment effectiveness is frequently quantified by analyzing overall survival (OS) and progression-free survival (PFS). In this paper we introduce a method for the joint network meta-analysis of PFS and OS that is based on a time-inhomogeneous tri-state (stable, progression, and death) Markov model where time-varying transition rates and relative treatment effects are modeled with known parametric survival functions or fractional polynomials. The data needed to run these analyses can be extracted directly from published survival curves. We demonstrate use by applying the methodology to a network of trials for the treatment of non-small-cell lung cancer. The proposed approach allows the joint synthesis of OS and PFS, relaxes the proportional hazards assumption, extends to a network of more than two treatments, and simplifies the parameterization of decision and cost-effectiveness analyses.

